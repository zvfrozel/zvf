{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_malayalam_word(word: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given word contains only Malayalam characters.\n",
    "    \n",
    "    Malayalam Unicode block is from U+0D00 to U+0D7F.\n",
    "    Whitespace is ignored.\n",
    "    \n",
    "    Args:\n",
    "        word: The string to check.\n",
    "        \n",
    "    Returns:\n",
    "        True if every non-whitespace character in the word is within the Malayalam block.\n",
    "    \"\"\"\n",
    "    for char in word:\n",
    "        if not char.isspace() and not (0x0D00 <= ord(char) <= 0x0D7F):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_malayalam_words(input_file: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Read Malayalam words from a file, filter and clean them according to specific rules,\n",
    "    and write the cleaned words to a new file.\n",
    "    \n",
    "    Cleaning steps:\n",
    "      - Strip leading/trailing whitespace.\n",
    "      - Remove empty lines.\n",
    "      - Discard lines with internal whitespace (i.e. multiple words).\n",
    "      - Discard words that are only one letter long.\n",
    "      - Keep only words that contain solely Malayalam characters.\n",
    "      - Remove duplicate words.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to the input file containing Malayalam words (one per line).\n",
    "        output_file: Path to the output file where cleaned words will be written.\n",
    "    \"\"\"\n",
    "    # Read all lines from the input file.\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "        lines = f_in.read().splitlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    seen = set()\n",
    "\n",
    "    for line in lines:\n",
    "        word = line.strip()\n",
    "        # Skip empty lines.\n",
    "        if not word:\n",
    "            continue\n",
    "        # Skip if there is any internal whitespace (i.e., multiple words).\n",
    "        if re.search(r\"\\s\", word):\n",
    "            continue\n",
    "        # Skip single-letter words.\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        # Check if the word is entirely Malayalam.\n",
    "        if is_malayalam_word(word) and word not in seen:\n",
    "            cleaned_lines.append(word)\n",
    "            seen.add(word)\n",
    "\n",
    "    # Write the cleaned words to the output file.\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for word in cleaned_lines:\n",
    "            f_out.write(word + \"\\n\")\n",
    "\n",
    "    print(\"Cleaning complete. See file:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete. See file: cleaned_ml_words.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"mlwiki-all-unique-words-20190101.txt\"\n",
    "    OUTPUT_FILE = \"cleaned_words_ml.txt\"\n",
    "    clean_malayalam_words(INPUT_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of vowel signs (we don't include \"ം\" and \"ഃ\", which are handled elsewhere)\n",
    "VOWEL_SIGNS = [\"ാ\", \"ി\", \"ീ\", \"ു\", \"ൂ\", \"ൃ\", \"െ\", \"േ\", \"ൈ\", \"ൊ\", \"ോ\", \"ൗ\"]\n",
    "# Virama character for reference (handled specially)\n",
    "VIRAMA = \"്\"\n",
    "\n",
    "\n",
    "def load_mapping(csv_filename: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load the transliteration mapping from a CSV file.\n",
    "    \n",
    "    Expects columns: Letter, Unicode, Unicode Name, RuneString, MachineString.\n",
    "    \n",
    "    Args:\n",
    "        csv_filename: Path to the CSV file containing the mapping.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping each letter or ligature to its transliteration.\n",
    "    \"\"\"\n",
    "    mapping: Dict[str, str] = {}\n",
    "    with open(csv_filename, encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            letter = row[\"Letter\"].strip()\n",
    "            translit = row[\"MachineString\"].strip()\n",
    "            if letter:\n",
    "                mapping[letter] = translit\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def transliterate_line(line: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Transliterate a line of text using a compiled regex that matches any key from the mapping.\n",
    "    \n",
    "    The alternatives in the regex are sorted in descending order of length so that longer\n",
    "    ligatures are prioritized.\n",
    "    \n",
    "    Special treatment:\n",
    "      - For vowel signs: if the output so far ends with an inherent \"A\", remove it before appending.\n",
    "      - For the virama: if the virama is at the end of a word (i.e. at line's end or followed by whitespace),\n",
    "        remove a trailing \"A\" from the output (if present) and append \"U\"; otherwise, simply remove the trailing \"A\".\n",
    "    \n",
    "    Args:\n",
    "        line: The input string to be transliterated.\n",
    "        mapping: A dictionary mapping letters/ligatures to their transliteration.\n",
    "    \n",
    "    Returns:\n",
    "        The transliterated line as a string.\n",
    "    \"\"\"\n",
    "    # Sort keys by descending length so that longer matches are prioritized.\n",
    "    sorted_keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    pattern = re.compile(\"|\".join(re.escape(key) for key in sorted_keys))\n",
    "\n",
    "    output = \"\"\n",
    "    last_index = 0\n",
    "\n",
    "    for m in pattern.finditer(line):\n",
    "        start, end = m.start(), m.end()\n",
    "        # Append unchanged text between matches.\n",
    "        output += line[last_index:start]\n",
    "        key = m.group(0)\n",
    "\n",
    "        if key == VIRAMA:\n",
    "            # For virama, remove trailing inherent \"A\" if present.\n",
    "            if output.endswith(\"A\"):\n",
    "                output = output[:-1]\n",
    "            # If the virama is at the end of a word, append \"U\".\n",
    "            if end == len(line) or (end < len(line) and line[end].isspace()):\n",
    "                output += \"U\"\n",
    "            # Otherwise, simply remove the inherent vowel (by doing nothing more).\n",
    "\n",
    "        elif key in VOWEL_SIGNS:\n",
    "            # For vowel signs, remove trailing inherent \"A\" before appending.\n",
    "            if output.endswith(\"A\"):\n",
    "                output = output[:-1]\n",
    "            output += mapping[key]\n",
    "\n",
    "        else:\n",
    "            output += mapping[key]\n",
    "\n",
    "        last_index = end\n",
    "\n",
    "    # Append any remaining text after the last match.\n",
    "    output += line[last_index:]\n",
    "    return output\n",
    "\n",
    "def transliterate_file(input_file: str, output_file: str, translit_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Load Malayalam words from the input file, transliterate them using a mapping from the CSV,\n",
    "    and write the transliterated text to the output file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to the file containing Malayalam words (one per line).\n",
    "        output_file: Path to the file where the transliterated output will be saved.\n",
    "        translit_key: Path to the CSV file with the transliteration mapping.\n",
    "    \"\"\"\n",
    "    # Load the transliteration mapping.\n",
    "    mapping = load_mapping(translit_key)\n",
    "\n",
    "    # Read the Malayalam words from the input file.\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "        lines = f_in.read().splitlines()\n",
    "\n",
    "    # Transliterate each line and write the result to the output file.\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for line in tqdm(lines, desc=\"Transliterating lines\", unit=\"line\"):\n",
    "            transliterated_line = transliterate_line(line, mapping)\n",
    "            f_out.write(transliterated_line + \"\\n\")\n",
    "\n",
    "    print(f\"Transliteration done. Saved to file {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transliterating lines: 100%|██████████| 1265902/1265902 [02:02<00:00, 10299.09line/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliteration done. See file:, MTWC_all.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"cleaned_ml_words.txt\"\n",
    "    OUTPUT_FILE = \"MTWC_all.txt\"\n",
    "    TRANSLIT_KEY = \"transliteration_key_ml.csv\"\n",
    "    transliterate_file(INPUT_FILE, OUTPUT_FILE, TRANSLIT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved to MTWC.csv.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Read input file and create DataFrame ---\n",
    "input_file = \"MTWC_all.txt\"  # Input text file containing words line separated\n",
    "output_csv = \"MTWC.csv\"  # Output CSV file\n",
    "rune_csv = \"runes_ml.csv\"  # Rune mapping CSV file\n",
    "\n",
    "# Read words from file into a DataFrame with column 'MachineWord'\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    words = f.read().splitlines()\n",
    "df = pd.DataFrame(words, columns=[\"MachineWord\"])\n",
    "\n",
    "# Compute the length and filter out words >15 characters in a vectorized way\n",
    "df[\"Length\"] = df[\"MachineWord\"].str.len()\n",
    "df = df[df[\"Length\"] <= 15].drop_duplicates(subset=\"MachineWord\").reset_index(drop=True)\n",
    "\n",
    "# --- Step 2: Load rune mapping from the rune CSV ---\n",
    "mapping_df = pd.read_csv(rune_csv, encoding=\"utf-8\")\n",
    "rune_mapping = dict(zip(mapping_df[\"MachineLetter\"], mapping_df[\"Rune\"]))\n",
    "\n",
    "# For multi-character tokens (e.g. \"[TT]\"), sort keys by length descending:\n",
    "keys = sorted(rune_mapping.keys(), key=len, reverse=True)\n",
    "pattern = re.compile(\"|\".join(map(re.escape, keys)))\n",
    "\n",
    "# --- Step 3: Create the new column 'RuneWord' using vectorized string replace ---\n",
    "# Pandas' str.replace accepts a callable when regex=True\n",
    "df[\"RuneWord\"] = df[\"MachineWord\"].str.replace(\n",
    "    pattern, lambda m: rune_mapping[m.group(0)], regex=True\n",
    ")\n",
    "\n",
    "# --- Step 4: Sort by Length ascending and reorder columns ---\n",
    "df = df.sort_values(\"Length\", ascending=True).reset_index(drop=True)\n",
    "df = df[[\"MachineWord\", \"RuneWord\", \"Length\"]]\n",
    "\n",
    "# --- Step 5: Save the final DataFrame to CSV ---\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"CSV file has been saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Read the CSV file ---\n",
    "df = pd.read_csv(\"MTWC.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Compute overall token frequencies by concatenating all MachineWord values and counting characters.\n",
    "overall_counter = Counter(\"\".join(df[\"MachineWord\"]))\n",
    "\n",
    "# Compute frequencies for words of length exactly 2 and 3 using vectorized filtering.\n",
    "counter_eq2 = Counter(\"\".join(df.loc[df[\"Length\"] == 2, \"MachineWord\"]))\n",
    "counter_eq3 = Counter(\"\".join(df.loc[df[\"Length\"] == 3, \"MachineWord\"]))\n",
    "\n",
    "# --- Step 2: Load rune mapping from \"runes_ml.csv\" ---\n",
    "mapping_df = pd.read_csv(\"runes_ml.csv\", encoding=\"utf-8\")\n",
    "rune_mapping = dict(zip(mapping_df[\"MachineLetter\"], mapping_df[\"Rune\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rune</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Freq_2</th>\n",
       "      <th>Freq_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MachineLetter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>A</td>\n",
       "      <td>1554922</td>\n",
       "      <td>6</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>I</td>\n",
       "      <td>510521</td>\n",
       "      <td>29</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>E</td>\n",
       "      <td>467329</td>\n",
       "      <td>32</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>U</td>\n",
       "      <td>465895</td>\n",
       "      <td>27</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>R</td>\n",
       "      <td>432149</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>N</td>\n",
       "      <td>391200</td>\n",
       "      <td>13</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>K</td>\n",
       "      <td>384470</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>M</td>\n",
       "      <td>303910</td>\n",
       "      <td>11</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>T</td>\n",
       "      <td>258754</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>Y</td>\n",
       "      <td>250173</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ʈ</th>\n",
       "      <td>[TT]</td>\n",
       "      <td>249794</td>\n",
       "      <td>7</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>S</td>\n",
       "      <td>240136</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>O</td>\n",
       "      <td>239908</td>\n",
       "      <td>29</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>L</td>\n",
       "      <td>232547</td>\n",
       "      <td>12</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>P</td>\n",
       "      <td>187586</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>H</td>\n",
       "      <td>176062</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>V</td>\n",
       "      <td>151157</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ƚ</th>\n",
       "      <td>[LL]</td>\n",
       "      <td>121625</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ɲ</th>\n",
       "      <td>[NN]</td>\n",
       "      <td>99135</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>G</td>\n",
       "      <td>94321</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>C</td>\n",
       "      <td>83273</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>B</td>\n",
       "      <td>65732</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>D</td>\n",
       "      <td>65346</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>J</td>\n",
       "      <td>49589</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ɗ</th>\n",
       "      <td>[DD]</td>\n",
       "      <td>41731</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>Z</td>\n",
       "      <td>15387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൌ</th>\n",
       "      <td>ൌ</td>\n",
       "      <td>2111</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>഼</th>\n",
       "      <td>഼</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>൯</th>\n",
       "      <td>൯</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഌ</th>\n",
       "      <td>ഌ</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഽ</th>\n",
       "      <td>ഽ</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഺ</th>\n",
       "      <td>ഺ</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൢ</th>\n",
       "      <td>ൢ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൎ</th>\n",
       "      <td>ൎ</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഩ</th>\n",
       "      <td>ഩ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൡ</th>\n",
       "      <td>ൡ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>൹</th>\n",
       "      <td>൹</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rune  Frequency  Freq_2  Freq_3\n",
       "MachineLetter                                 \n",
       "A                 A    1554922       6     489\n",
       "I                 I     510521      29     283\n",
       "E                 E     467329      32     272\n",
       "U                 U     465895      27     285\n",
       "R                 R     432149      12      84\n",
       "N                 N     391200      13     172\n",
       "K                 K     384470       7     102\n",
       "M                 M     303910      11     126\n",
       "T                 T     258754       5      67\n",
       "Y                 Y     250173       4      71\n",
       "Ʈ              [TT]     249794       7      88\n",
       "S                 S     240136       4      90\n",
       "O                 O     239908      29     193\n",
       "L                 L     232547      12     147\n",
       "P                 P     187586       4      69\n",
       "H                 H     176062       4      80\n",
       "V                 V     151157       4      57\n",
       "Ƚ              [LL]     121625       7      53\n",
       "Ɲ              [NN]      99135      11      88\n",
       "G                 G      94321       4      50\n",
       "C                 C      83273       4      43\n",
       "B                 B      65732       6      58\n",
       "D                 D      65346       5      54\n",
       "J                 J      49589       4      39\n",
       "Ɗ              [DD]      41731       5      59\n",
       "Z                 Z      15387       0       1\n",
       "ൌ                 ൌ       2111       0      15\n",
       "഼                 ഼        230       1       0\n",
       "൯                 ൯         62       2       0\n",
       "ഌ                 ഌ         55       0       0\n",
       "ഽ                 ഽ          9       0       0\n",
       "ഺ                 ഺ          7       3       0\n",
       "ൢ                 ൢ          3       1       0\n",
       "ൎ                 ൎ          3       0       0\n",
       "ഩ                 ഩ          2       1       0\n",
       "ൡ                 ൡ          1       0       0\n",
       "൹                 ൹          1       0       0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    (\n",
    "        token,\n",
    "        rune_mapping.get(token, token),\n",
    "        freq,\n",
    "        counter_eq2.get(token, 0),\n",
    "        counter_eq3.get(token, 0),\n",
    "    )\n",
    "    for token, freq in overall_counter.items()\n",
    "]\n",
    "\n",
    "freqs = pd.DataFrame(\n",
    "    data, columns=[\"MachineLetter\", \"Rune\", \"Frequency\", \"Freq_2\", \"Freq_3\"]\n",
    ")\n",
    "freqs = freqs.sort_values(\"Frequency\", ascending=False).set_index(\"MachineLetter\")\n",
    "\n",
    "freqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

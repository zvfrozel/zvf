{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import Dict, Optional, Pattern\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_malayalam_word(word: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if every non-whitespace character in the word\n",
    "    is within the Malayalam Unicode block (U+0D00 to U+0D7F).\n",
    "    \"\"\"\n",
    "    return all(char.isspace() or 0x0D00 <= ord(char) <= 0x0D7F for char in word)\n",
    "\n",
    "\n",
    "def clean_malayalam_words(input_file: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Read Malayalam words from a file, clean them by:\n",
    "      - Stripping whitespace,\n",
    "      - Removing empty lines and words with internal whitespace or only one letter,\n",
    "      - Keeping only words that contain solely Malayalam characters,\n",
    "      - Removing duplicate words.\n",
    "    Write the cleaned words to a new file.\n",
    "    \"\"\"\n",
    "    internal_whitespace = re.compile(r\"\\s\")\n",
    "    seen = set()\n",
    "    cleaned_lines = []\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word = line.strip()\n",
    "            if not word or internal_whitespace.search(word) or len(word) == 1:\n",
    "                continue\n",
    "            if is_malayalam_word(word) and word not in seen:\n",
    "                cleaned_lines.append(word)\n",
    "                seen.add(word)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(cleaned_lines) + \"\\n\")\n",
    "\n",
    "    print(\"Cleaning complete. See file:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete. See file: cleaned_words_ml.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"mlwiki-all-unique-words-20190101.txt\"\n",
    "    OUTPUT_FILE = \"cleaned_words_ml.txt\"\n",
    "    clean_malayalam_words(INPUT_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOWEL_SIGNS = [\"ാ\", \"ി\", \"ീ\", \"ു\", \"ൂ\", \"ൃ\", \"െ\", \"േ\", \"ൈ\", \"ൊ\", \"ോ\", \"ൗ\"]\n",
    "VIRAMA = \"്\"\n",
    "\n",
    "\n",
    "def load_mapping(csv_filename: str) -> Dict[str, str]:\n",
    "    \"\"\"Load transliteration mapping from a CSV file (expects columns 'Letter' and 'MachineString').\"\"\"\n",
    "    with open(csv_filename, encoding=\"utf-8\") as csvfile:\n",
    "        return {\n",
    "            row[\"Letter\"].strip(): row[\"MachineString\"].strip()\n",
    "            for row in csv.DictReader(csvfile)\n",
    "            if row[\"Letter\"].strip()\n",
    "        }\n",
    "\n",
    "\n",
    "def translit_line(\n",
    "    line: str, mapping: Dict[str, str], pattern: Optional[Pattern] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Transliterate a line using the provided mapping.\n",
    "\n",
    "    Handles vowel signs and the virama specially:\n",
    "      - For vowel signs: if output ends with \"A\", remove it before appending.\n",
    "      - For the virama: if at the word's end, remove a trailing \"A\" (if present) and append \"U\".\n",
    "    \"\"\"\n",
    "    if pattern is None:\n",
    "        sorted_keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "        pattern = re.compile(\"|\".join(map(re.escape, sorted_keys)))\n",
    "\n",
    "    output = \"\"\n",
    "    last_index = 0\n",
    "    for m in pattern.finditer(line):\n",
    "        start, end = m.start(), m.end()\n",
    "        output += line[last_index:start]\n",
    "        key = m.group(0)\n",
    "        if key == VIRAMA:\n",
    "            if output.endswith(\"A\"):\n",
    "                output = output[:-1]\n",
    "            if end == len(line) or (end < len(line) and line[end].isspace()):\n",
    "                output += \"U\"\n",
    "        elif key in VOWEL_SIGNS:\n",
    "            if output.endswith(\"A\"):\n",
    "                output = output[:-1]\n",
    "            output += mapping[key]\n",
    "        else:\n",
    "            output += mapping[key]\n",
    "        last_index = end\n",
    "    output += line[last_index:]\n",
    "    return output\n",
    "\n",
    "\n",
    "def translit_file(input_file: str, output_file: str, translit_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Load Malayalam words from the input file,\n",
    "    transliterate each line using the mapping from the CSV,\n",
    "    and write the transliterated output to the output file.\n",
    "    \"\"\"\n",
    "    mapping = load_mapping(translit_key)\n",
    "    sorted_keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, sorted_keys)))\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "        lines = f_in.read().splitlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for line in tqdm(lines, desc=\"Transliterating lines\", unit=\"line\"):\n",
    "            f_out.write(translit_line(line, mapping, pattern) + \"\\n\")\n",
    "\n",
    "    print(f\"Transliteration done. Saved to file {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transliterating lines: 100%|██████████| 1265902/1265902 [00:27<00:00, 45682.53line/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliteration done. Saved to file MTWC_all.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"cleaned_words_ml.txt\"\n",
    "    OUTPUT_FILE = \"MTWC_all.txt\"\n",
    "    TRANSLIT_KEY = \"translit_key_ml.csv\"\n",
    "    translit_file(INPUT_FILE, OUTPUT_FILE, TRANSLIT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(df: pd.DataFrame, max_length: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Filter words longer than max_length and remove duplicates; add a 'Length' column.\"\"\"\n",
    "    df[\"Length\"] = df[\"MachineWord\"].str.len()\n",
    "    return (\n",
    "        df[df[\"Length\"] <= max_length]\n",
    "        .drop_duplicates(\"MachineWord\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_rune_mapping(df: pd.DataFrame, rune_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"Create 'RuneWord' column by replacing tokens in 'MachineWord' using the rune mapping.\"\"\"\n",
    "    mapping_df = pd.read_csv(rune_csv, encoding=\"utf-8\")\n",
    "    mapping = dict(zip(mapping_df[\"MachineLetter\"], mapping_df[\"Rune\"]))\n",
    "    keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, keys)))\n",
    "    df[\"RuneWord\"] = df[\"MachineWord\"].str.replace(\n",
    "        pattern, lambda m: mapping[m.group(0)], regex=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_lexicon(input_file: str, output_csv: str, rune_csv: str) -> None:\n",
    "    \"\"\"\n",
    "    Clean the lexicon by loading words, filtering them, applying the rune mapping,\n",
    "    sorting by word length, and saving to CSV.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = f.read().splitlines()\n",
    "    df = pd.DataFrame(words, columns=[\"MachineWord\"])\n",
    "    df = filter_words(df)\n",
    "    df = apply_rune_mapping(df, rune_csv)\n",
    "    df = df.sort_values(\"Length\").reset_index(drop=True)[\n",
    "        [\"MachineWord\", \"RuneWord\", \"Length\"]\n",
    "    ]\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"CSV file saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to MTWC.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"MTWC_all.txt\"\n",
    "    OUTPUT_CSV = \"MTWC.csv\"\n",
    "    RUNE_CSV = \"runes_ml.csv\"\n",
    "    clean_lexicon(INPUT_FILE, OUTPUT_CSV, RUNE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequencies(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Compute token frequencies for all words and for words of length 2 and 3.\"\"\"\n",
    "    overall = Counter(\"\".join(df[\"MachineWord\"]))\n",
    "    eq2 = Counter(\"\".join(df.loc[df[\"Length\"] == 2, \"MachineWord\"]))\n",
    "    eq3 = Counter(\"\".join(df.loc[df[\"Length\"] == 3, \"MachineWord\"]))\n",
    "    return overall, eq2, eq3\n",
    "\n",
    "\n",
    "def create_frequency_dataframe(lexicon_csv: str, rune_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame with tokens, their runes, overall frequency, and frequencies for words\n",
    "    of length 2 and 3. The resulting DataFrame is sorted by descending Frequency and indexed by MachineLetter.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(lexicon_csv, encoding=\"utf-8\")\n",
    "    overall, eq2, eq3 = compute_frequencies(df)\n",
    "    rune_mapping = (\n",
    "        pd.read_csv(rune_csv, encoding=\"utf-8\")\n",
    "        .set_index(\"MachineLetter\")[\"Rune\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "    data = [\n",
    "        (\n",
    "            token,\n",
    "            rune_mapping.get(token, token),\n",
    "            freq,\n",
    "            eq2.get(token, 0),\n",
    "            eq3.get(token, 0),\n",
    "        )\n",
    "        for token, freq in overall.items()\n",
    "    ]\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            data, columns=[\"MachineLetter\", \"Rune\", \"Frequency\", \"Freq_2\", \"Freq_3\"]\n",
    "        )\n",
    "        .sort_values(\"Frequency\", ascending=False)\n",
    "        .set_index(\"MachineLetter\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    LEXICON_CSV = \"MTWC.csv\"\n",
    "    RUNE_CSV = \"runes_ml.csv\"\n",
    "    freqs = create_frequency_dataframe(LEXICON_CSV, RUNE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rune</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Freq_2</th>\n",
       "      <th>Freq_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MachineLetter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>A</td>\n",
       "      <td>1541451</td>\n",
       "      <td>6</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>I</td>\n",
       "      <td>527907</td>\n",
       "      <td>29</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>E</td>\n",
       "      <td>493391</td>\n",
       "      <td>31</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>U</td>\n",
       "      <td>483223</td>\n",
       "      <td>27</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>R</td>\n",
       "      <td>446994</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>N</td>\n",
       "      <td>404701</td>\n",
       "      <td>13</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>K</td>\n",
       "      <td>402635</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>M</td>\n",
       "      <td>313566</td>\n",
       "      <td>11</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>T</td>\n",
       "      <td>269052</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ʈ</th>\n",
       "      <td>[TT]</td>\n",
       "      <td>260516</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>Y</td>\n",
       "      <td>259250</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>S</td>\n",
       "      <td>250289</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>L</td>\n",
       "      <td>239934</td>\n",
       "      <td>12</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>P</td>\n",
       "      <td>197183</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>H</td>\n",
       "      <td>184329</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>V</td>\n",
       "      <td>156056</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>O</td>\n",
       "      <td>130748</td>\n",
       "      <td>28</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ƚ</th>\n",
       "      <td>[LL]</td>\n",
       "      <td>127396</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ɲ</th>\n",
       "      <td>[NN]</td>\n",
       "      <td>103078</td>\n",
       "      <td>11</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>G</td>\n",
       "      <td>97803</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>C</td>\n",
       "      <td>86403</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>D</td>\n",
       "      <td>68864</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>B</td>\n",
       "      <td>67000</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>J</td>\n",
       "      <td>50988</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ɗ</th>\n",
       "      <td>[DD]</td>\n",
       "      <td>42671</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>Z</td>\n",
       "      <td>15937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>഼</th>\n",
       "      <td>഼</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>൯</th>\n",
       "      <td>൯</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഌ</th>\n",
       "      <td>ഌ</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഽ</th>\n",
       "      <td>ഽ</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഺ</th>\n",
       "      <td>ഺ</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൢ</th>\n",
       "      <td>ൢ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൎ</th>\n",
       "      <td>ൎ</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ഩ</th>\n",
       "      <td>ഩ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ൡ</th>\n",
       "      <td>ൡ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>൹</th>\n",
       "      <td>൹</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rune  Frequency  Freq_2  Freq_3\n",
       "MachineLetter                                 \n",
       "A                 A    1541451       6     463\n",
       "I                 I     527907      29     288\n",
       "E                 E     493391      31     335\n",
       "U                 U     483223      27     289\n",
       "R                 R     446994      12      88\n",
       "N                 N     404701      13     174\n",
       "K                 K     402635       7     103\n",
       "M                 M     313566      11     135\n",
       "T                 T     269052       5      71\n",
       "Ʈ              [TT]     260516       7      91\n",
       "Y                 Y     259250       4      75\n",
       "S                 S     250289       4      94\n",
       "L                 L     239934      12     152\n",
       "P                 P     197183       4      71\n",
       "H                 H     184329       4      84\n",
       "V                 V     156056       4      66\n",
       "O                 O     130748      28     180\n",
       "Ƚ              [LL]     127396       7      69\n",
       "Ɲ              [NN]     103078      11      98\n",
       "G                 G      97803       4      54\n",
       "C                 C      86403       4      46\n",
       "D                 D      68864       5      57\n",
       "B                 B      67000       6      64\n",
       "J                 J      50988       4      40\n",
       "Ɗ              [DD]      42671       5      64\n",
       "Z                 Z      15937       0       1\n",
       "഼                 ഼        236       1       0\n",
       "൯                 ൯         63       2       0\n",
       "ഌ                 ഌ         55       0       0\n",
       "ഽ                 ഽ         10       0       0\n",
       "ഺ                 ഺ          7       3       0\n",
       "ൢ                 ൢ          3       1       0\n",
       "ൎ                 ൎ          3       0       0\n",
       "ഩ                 ഩ          2       1       0\n",
       "ൡ                 ൡ          1       0       0\n",
       "൹                 ൹          1       0       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
